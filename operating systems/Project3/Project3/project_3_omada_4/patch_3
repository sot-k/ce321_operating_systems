diff -ruN linux-3.14.62-orig/arch/x86/syscalls/syscall_32.tbl linux-3.14.62-dev/arch/x86/syscalls/syscall_32.tbl
--- linux-3.14.62-orig/arch/x86/syscalls/syscall_32.tbl	2016-02-25 21:59:45.000000000 +0200
+++ linux-3.14.62-dev/arch/x86/syscalls/syscall_32.tbl	2017-05-11 20:58:46.967261002 +0300
@@ -359,3 +359,5 @@
 350	i386	finit_module		sys_finit_module
 351	i386	sched_setattr		sys_sched_setattr
 352	i386	sched_getattr		sys_sched_getattr
+353	i386	slob_get_total_alloc_mem	sys_slob_get_total_alloc_mem
+354	i386	slob_get_total_free_mem		sys_slob_get_total_free_mem
\ No newline at end of file
diff -ruN linux-3.14.62-orig/include/linux/slob_functions.h linux-3.14.62-dev/include/linux/slob_functions.h
--- linux-3.14.62-orig/include/linux/slob_functions.h	1970-01-01 02:00:00.000000000 +0200
+++ linux-3.14.62-dev/include/linux/slob_functions.h	2017-05-11 21:05:25.702565000 +0300
@@ -0,0 +1,3 @@
+long get_total_alloc_mem(void);
+
+long get_total_free_mem(void);
\ No newline at end of file
diff -ruN linux-3.14.62-orig/include/linux/syscalls.h linux-3.14.62-dev/include/linux/syscalls.h
--- linux-3.14.62-orig/include/linux/syscalls.h	2016-02-25 21:59:45.000000000 +0200
+++ linux-3.14.62-dev/include/linux/syscalls.h	2017-05-11 20:57:48.703261002 +0300
@@ -855,4 +855,6 @@
 asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
 			 unsigned long idx1, unsigned long idx2);
 asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+asmlinkage long sys_slob_get_total_alloc_mem(void);
+asmlinkage long sys_slob_get_total_free_mem(void);
 #endif
diff -ruN linux-3.14.62-orig/kernel/alloc_mem.c linux-3.14.62-dev/kernel/alloc_mem.c
--- linux-3.14.62-orig/kernel/alloc_mem.c	1970-01-01 02:00:00.000000000 +0200
+++ linux-3.14.62-dev/kernel/alloc_mem.c	2017-05-11 22:16:45.045385345 +0300
@@ -0,0 +1,9 @@
+#include <linux/kernel.h>
+#include <linux/syscalls.h>
+
+#include <linux/slob_functions.h>
+
+SYSCALL_DEFINE0(slob_get_total_alloc_mem){
+	long allocated = get_total_alloc_mem();
+	return(allocated);
+}
\ No newline at end of file
diff -ruN linux-3.14.62-orig/kernel/free_mem.c linux-3.14.62-dev/kernel/free_mem.c
--- linux-3.14.62-orig/kernel/free_mem.c	1970-01-01 02:00:00.000000000 +0200
+++ linux-3.14.62-dev/kernel/free_mem.c	2017-05-11 22:16:47.105385345 +0300
@@ -0,0 +1,9 @@
+#include <linux/kernel.h>
+#include <linux/syscalls.h>
+
+#include <linux/slob_functions.h>
+
+SYSCALL_DEFINE0(slob_get_total_free_mem){
+	long free = get_total_free_mem();
+	return(free);
+}
\ No newline at end of file
diff -ruN linux-3.14.62-orig/kernel/Makefile linux-3.14.62-dev/kernel/Makefile
--- linux-3.14.62-orig/kernel/Makefile	2016-02-25 21:59:45.000000000 +0200
+++ linux-3.14.62-dev/kernel/Makefile	2017-05-11 21:01:14.431261002 +0300
@@ -10,7 +10,9 @@
 	    kthread.o sys_ni.o posix-cpu-timers.o \
 	    hrtimer.o nsproxy.o \
 	    notifier.o ksysfs.o cred.o reboot.o \
-	    async.o range.o groups.o smpboot.o
+	    async.o range.o groups.o smpboot.o \
+	    alloc_mem.o free_mem.o
+
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff -ruN linux-3.14.62-orig/Makefile linux-3.14.62-dev/Makefile
--- linux-3.14.62-orig/Makefile	2016-02-25 21:59:45.000000000 +0200
+++ linux-3.14.62-dev/Makefile	2017-05-11 17:32:32.726022000 +0300
@@ -1,7 +1,7 @@
 VERSION = 3
 PATCHLEVEL = 14
 SUBLEVEL = 62
-EXTRAVERSION =
+EXTRAVERSION = -dev
 NAME = Remembering Coco
 
 # *DOCUMENTATION*
diff -ruN linux-3.14.62-orig/mm/slob.c linux-3.14.62-dev/mm/slob.c
--- linux-3.14.62-orig/mm/slob.c	2016-02-25 21:59:45.000000000 +0200
+++ linux-3.14.62-dev/mm/slob.c	2017-05-12 18:09:58.406399710 +0300
@@ -73,6 +73,23 @@
 #include <linux/atomic.h>
 
 #include "slab.h"
+#include <linux/slob_functions.h>
+
+#define MAX_PAGE_SIZE 40000000
+//#define BEST_FIT
+#define FIRST_FIT
+
+static long free_mem = 0, total_mem;
+//static unsigned int calls = 0;
+
+long get_total_alloc_mem(void){
+	return(total_mem);
+}
+
+long get_total_free_mem(void){
+	return(free_mem);
+}
+
 /*
  * slob_block has a field 'units', which indicates size of block if +ve,
  * or offset of next block if -ve (in SLOB_UNITs).
@@ -201,6 +218,9 @@
 	if (!page)
 		return NULL;
 
+	//total_mem += sizeof(page);
+	total_mem += SLOB_UNITS(PAGE_SIZE);	
+
 	return page_address(page);
 }
 
@@ -209,6 +229,9 @@
 	if (current->reclaim_state)
 		current->reclaim_state->reclaimed_slab += 1 << order;
 	free_pages((unsigned long)b, order);
+
+	//total_mem -= sizeof(b);
+	total_mem -= SLOB_UNITS(PAGE_SIZE);
 }
 
 /*
@@ -218,61 +241,165 @@
 {
 	slob_t *prev, *cur, *aligned = NULL;
 	int delta = 0, units = SLOB_UNITS(size);
+	static unsigned int calls = 0;	
 
-	for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
-		slobidx_t avail = slob_units(cur);
+	#ifdef BEST_FIT	//Best Fit
+		slob_t *prev_best = NULL, *cur_best = NULL, *aligned_best = NULL;
+		int delta_best = 0;
+		slobidx_t best_fit = 0;
+		slobidx_t avail;
+
+		calls++;
+		
+		if (calls == 6000) {
+			printk("slob_alloc: Request: %u\nslob_alloc: Candidate blocks size:", units);
+		}
 
-		if (align) {
-			aligned = (slob_t *)ALIGN((unsigned long)cur, align);
-			delta = aligned - cur;
+		for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
+			avail = slob_units(cur);
+
+			if (align) {
+				aligned = (slob_t *)ALIGN((unsigned long)cur, align);
+				delta = aligned - cur;
+			}
+
+			if (avail >= (units + delta)) {
+				if (calls == 6000) {
+				 	printk(" %d", avail-delta);
+				}
+				
+				if ((cur_best == NULL) || (avail - (units + delta) < best_fit)) {
+					prev_best = prev;
+					cur_best = cur;
+					aligned_best = aligned;
+					delta_best = delta;
+					best_fit = avail - (units + delta);
+				}
+			}
+
+			if (slob_last(cur)){
+				if (cur_best != NULL){
+					slob_t * next_best = NULL;
+					slobidx_t avail_best = slob_units(cur_best);
+
+					if (delta_best) {/* need to fragment head to align? */
+						next_best = slob_next(cur_best);
+						set_slob(aligned_best, avail_best - delta_best, next_best);
+						set_slob(cur_best, delta_best, aligned_best);
+						prev_best = cur_best;
+						cur_best = aligned_best;
+						avail_best = slob_units(cur_best);
+					}
+
+					if (calls == 6000) {
+						printk("\nslob_alloc: Best fit: %d\n\n", best_fit + units);
+					 	calls = 0;
+					 }
+
+					next_best = slob_next(cur_best);
+
+					if (avail_best == units) { /* exact fit? unlink. */
+						if (prev_best)
+							set_slob(prev_best, slob_units(prev_best), next_best);
+						else
+							sp->freelist = next_best;
+					} else { /* fragment */
+						if (prev_best)
+							set_slob(prev_best, slob_units(prev_best), cur_best + units);
+						else
+							sp->freelist = cur_best + units;
+						set_slob(cur_best + units, avail_best - units, next_best);
+					}
+
+					sp->units -= units;
+					if (!sp->units)
+						clear_slob_page_free(sp);
+					return cur_best;
+				}
+				
+				if (calls == 6000) {
+					printk("\nslob_alloc: Best fit: None\n\n");
+					calls = 0;
+				}	
+
+				//go to other page		
+				return NULL;
+			}
 		}
-		if (avail >= units + delta) { /* room enough? */
-			slob_t *next;
+	#endif
+	//#else
+	#ifdef FIRST_FIT	//First Fit
+		for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
+			slobidx_t avail = slob_units(cur);
+
+			if (align) {
+				aligned = (slob_t *)ALIGN((unsigned long)cur, align);
+				delta = aligned - cur;
+			}
+			if (avail >= units + delta) { /* room enough? */
+				slob_t *next;
+
+				if (delta) { /* need to fragment head to align? */
+					next = slob_next(cur);
+					set_slob(aligned, avail - delta, next);
+					set_slob(cur, delta, aligned);
+					prev = cur;
+					cur = aligned;
+					avail = slob_units(cur);
+				}
 
-			if (delta) { /* need to fragment head to align? */
 				next = slob_next(cur);
-				set_slob(aligned, avail - delta, next);
-				set_slob(cur, delta, aligned);
-				prev = cur;
-				cur = aligned;
-				avail = slob_units(cur);
-			}
-
-			next = slob_next(cur);
-			if (avail == units) { /* exact fit? unlink. */
-				if (prev)
-					set_slob(prev, slob_units(prev), next);
-				else
-					sp->freelist = next;
-			} else { /* fragment */
-				if (prev)
-					set_slob(prev, slob_units(prev), cur + units);
-				else
-					sp->freelist = cur + units;
-				set_slob(cur + units, avail - units, next);
-			}
-
-			sp->units -= units;
-			if (!sp->units)
-				clear_slob_page_free(sp);
-			return cur;
+				if (avail == units) { /* exact fit? unlink. */
+					if (prev)
+						set_slob(prev, slob_units(prev), next);
+					else
+						sp->freelist = next;
+				} else { /* fragment */
+					if (prev)
+						set_slob(prev, slob_units(prev), cur + units);
+					else
+						sp->freelist = cur + units;
+					set_slob(cur + units, avail - units, next);
+				}
+
+				sp->units -= units;
+				if (!sp->units)
+					clear_slob_page_free(sp);
+				return cur;
+			}
+			if (slob_last(cur))
+				return NULL;
 		}
-		if (slob_last(cur))
-			return NULL;
-	}
+	#endif
+
 }
 
 /*
  * slob_alloc: entry point into the slob allocator.
  */
+
 static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 {
 	struct page *sp;
-	struct list_head *prev;
+	//struct list_head *prev;
 	struct list_head *slob_list;
 	slob_t *b = NULL;
 	unsigned long flags;
 
+	struct page *sp_best = NULL;
+	int best_fit = -1, page_fit = -1;
+
+	//variables for fit check
+	slob_t *prv = NULL, *cur = NULL, *aligned = NULL;
+	int delta = 0, units = SLOB_UNITS(size);
+
+	slob_t *cur_best = NULL;
+	slobidx_t fit_check = 0;
+	slobidx_t avail;
+
+	//Variable to find the minimum page
+	int best_page = MAX_PAGE_SIZE;
+
 	if (size < SLOB_BREAK1)
 		slob_list = &free_slob_small;
 	else if (size < SLOB_BREAK2)
@@ -282,7 +409,9 @@
 
 	spin_lock_irqsave(&slob_lock, flags);
 	/* Iterate through each partially free page, try to find room */
+	
 	list_for_each_entry(sp, slob_list, list) {
+
 #ifdef CONFIG_NUMA
 		/*
 		 * If there's a node specification, search for a partial
@@ -292,23 +421,90 @@
 			continue;
 #endif
 		/* Enough room on this page? */
-		if (sp->units < SLOB_UNITS(size))
+		if (sp->units < units)
 			continue;
 
-		/* Attempt to alloc */
-		prev = sp->list.prev;
-		b = slob_page_alloc(sp, size, align);
-		if (!b)
+		if (sp->units > best_page)
 			continue;
+		
+		/*~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+		* This code has the same functionality as slob_page_alloc
+ 		* but it doesn't allocate the memory
+ 		* At the end  page_fit will take one of the following values:
+ 		* -1 if the current request doesn't fit in the current page
+ 		* 0 if it is an exact fit
+ 		* and a positive number if there are units remaining in the page*/
+
+		for (prv = NULL, cur = sp->freelist; ; prv = cur, cur = slob_next(cur)) {
+			avail = slob_units(cur);
+
+			if (align) {
+				aligned = (slob_t *) ALIGN((unsigned long)cur, align);
+				delta = aligned - cur;
+			}
 
-		/* Improve fragment distribution and reduce our average
-		 * search time by starting our next search here. (see
-		 * Knuth vol 1, sec 2.5, pg 449) */
-		if (prev != slob_list->prev &&
-				slob_list->next != prev->next)
-			list_move_tail(slob_list, prev->next);
-		break;
+			if ((avail >= (units + delta)) && ((cur_best == NULL) || (avail - (units + delta) < fit_check))){
+				cur_best = cur;
+				fit_check = avail - (units + delta);
+				page_fit = 0;
+				if (fit_check == 0) { // exact fit
+					page_fit = 1;
+					break;
+				}
+			}
+			if (slob_last(cur)) {
+				break;
+			}
+		}
+		/*~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*/
+		
+		//if (sp->units < units)
+		//	continue;
+
+		//if (sp->units > best_page)
+		//	continue;
+
+		if (page_fit == 1) { /*exact fit*/
+			sp_best = sp;
+			best_fit = fit_check;
+			b = slob_page_alloc(sp, size, align);
+			break;
+		}
+		else if ((page_fit == 0) && (best_fit == -1 || fit_check < best_fit)) {
+			sp_best = sp;
+			best_fit = fit_check;
+			best_page = sp->units;
+		}
+
+		if (best_fit >= 0) {
+			/* Attempt to alloc */
+			//prev = sp_best->list.prev;
+			sp_best = sp;
+			b = slob_page_alloc(sp, size, align);
+			if(list_last_entry(slob_list, typeof(*sp), list) == sp){ /*finds the end and exits */
+              			break;
+            		}
+        	}
+		else {
+            		continue;
+        	}
+
+        	if(!b)
+            		continue;
+  		break;
 	}
+
+
+	//Calculate free memory
+	
+	free_mem = 0;
+	list_for_each_entry(sp, &free_slob_small, list)
+		free_mem += sp->units*SLOB_UNIT;
+	list_for_each_entry(sp, &free_slob_medium, list)
+		free_mem += sp->units*SLOB_UNIT;
+	list_for_each_entry(sp, &free_slob_large, list)
+		free_mem += sp->units*SLOB_UNIT;
+	
 	spin_unlock_irqrestore(&slob_lock, flags);
 
 	/* Not enough space: must allocate a new page */
diff -ruN linux-3.14.62-orig/security/tomoyo/builtin-policy.h linux-3.14.62-dev/security/tomoyo/builtin-policy.h
--- linux-3.14.62-orig/security/tomoyo/builtin-policy.h	1970-01-01 02:00:00.000000000 +0200
+++ linux-3.14.62-dev/security/tomoyo/builtin-policy.h	2017-05-11 17:49:54.626022000 +0300
@@ -0,0 +1,12 @@
+static char tomoyo_builtin_profile[] __initdata =
+"";
+static char tomoyo_builtin_exception_policy[] __initdata =
+"initialize_domain /sbin/modprobe from any\n"
+"initialize_domain /sbin/hotplug from any\n"
+"";
+static char tomoyo_builtin_domain_policy[] __initdata =
+"";
+static char tomoyo_builtin_manager[] __initdata =
+"";
+static char tomoyo_builtin_stat[] __initdata =
+"";
diff -ruN linux-3.14.62-orig/security/tomoyo/policy/exception_policy.conf linux-3.14.62-dev/security/tomoyo/policy/exception_policy.conf
--- linux-3.14.62-orig/security/tomoyo/policy/exception_policy.conf	1970-01-01 02:00:00.000000000 +0200
+++ linux-3.14.62-dev/security/tomoyo/policy/exception_policy.conf	2017-05-11 17:49:54.594022000 +0300
@@ -0,0 +1,2 @@
+initialize_domain /sbin/modprobe from any
+initialize_domain /sbin/hotplug from any
